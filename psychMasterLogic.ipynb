{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63930504",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%pip install langchain_groq\n",
    "%pip install langchain_core langchain_community\n",
    "%pip install pypdf\n",
    "%pip install chromadb\n",
    "%pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d066681f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%pip uninstall -y keras tensorflow\n",
    "%pip install tensorflow==2.15.0 tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2020f5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq (\n",
    "    temperature =0,\n",
    "    groq_api_key =\"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\", \n",
    "    model_name =\"llama-3.3-70b-versatile\"\n",
    ")\n",
    "\n",
    "result = llm.invoke(\"how do u feel after listening to word Anmol\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8036b093",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os \n",
    "\n",
    "def initialize_llm():\n",
    "    llm = ChatGroq (\n",
    "    temperature =0,\n",
    "    groq_api_key =\"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\", \n",
    "    model_name =\"llama-3.3-70b-versatile\"\n",
    ")\n",
    "    return llm\n",
    "\n",
    "\n",
    "def create_vector_db():\n",
    "    loader = DirectoryLoader(\"/content/\", glob=\"*.pdf\", loader_cls= PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    embeddings = HuggingFaceBgeEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2')\n",
    "    vector_db = Chroma.from_documents(texts, embeddings, persist_directory='./chroma_db')\n",
    "    vector_db.persist()\n",
    "\n",
    "    print(\"chroma db created and data saved\")\n",
    "\n",
    "    return vector_db\n",
    "\n",
    "def setup_qa_chain(vector_db, llm):\n",
    "    retriever = vector_db.as_retriever()\n",
    "    prompt_templates=\"\"\"  \n",
    "\n",
    "    mental health chatbot \n",
    "    {context}\n",
    "    User : {question}    \n",
    "    Chatbot:\"\"\"\n",
    "    \n",
    "    PROMPT = PromptTemplate(template = prompt_templates, input_variables=['context', 'question'])\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm = llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever = retriever,\n",
    "        chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "    )\n",
    "    return qa_chain\n",
    "\n",
    "  \n",
    "def main():\n",
    "  print(\"chatbot started\")\n",
    "  llm = initialize_llm()\n",
    "\n",
    "  db_path = \"/content/chroma_db\"\n",
    "\n",
    "  if not os.path.exists(db_path):\n",
    "    vector_db = create_vector_db()\n",
    "  else:\n",
    "    embeddings = HuggingFaceBgeEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2')\n",
    "    vector_db = Chroma(persist_directory=db_path, embedding_function=embeddings)\n",
    "  qa_chain = setup_qa_chain(vector_db, llm)\n",
    "\n",
    "  while True:\n",
    "    query = input(\"\\nHuman: \")\n",
    "    if query.lower() == \"exit\":\n",
    "      print(\"ChatBot: Take Care\")\n",
    "      break\n",
    "    response = qa_chain.run(query)\n",
    "    print(f\"Chatbot: {response}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043a1140",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "create_vector_db()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
